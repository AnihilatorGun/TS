{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3608b4ce-9598-4ec0-b899-d2945173ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68075c5-7baa-41fb-9a71-6ee9115bc6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69940\n"
     ]
    }
   ],
   "source": [
    "from pyfillet import TextEmbedder\n",
    "\n",
    "data = 0\n",
    "with open('TrainingData/schizophrenia.txt') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "text = ''\n",
    "for string in data:\n",
    "    text += string\n",
    "\n",
    "embedder = TextEmbedder()\n",
    "embeddings = embedder(text)\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c8ac6d9-91d9-48d6-927a-e0c2670425b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bar = {}\n",
    "for obj in embeddings:\n",
    "    bar[obj[0]] = torch.tensor(obj[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89f1a8f0-8ac9-4837-8b56-74c478d3ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(torch.nn.Module):\n",
    "    def __init__(self, embedding_dict):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Linear(300*2, 256),  # Eats 2 vec-words, return vec-word\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 300))\n",
    "        self.embedding_dict = embedding_dict\n",
    "        \n",
    "    def the_most_similar(self, embedded_vector):  # tries to find the most similar word with respect to vec-word\n",
    "        word = ''\n",
    "        least_distance = 1000000.0\n",
    "        for key, value in self.embedding_dict.items():\n",
    "            if least_distance >= float((embedded_vector - value).dot(embedded_vector - value)):\n",
    "                word = key\n",
    "        return word\n",
    "        \n",
    "    def forward(self, prev_words):\n",
    "        input = torch.tensor([])\n",
    "        for word in prev_words:\n",
    "            input = torch.cat((input, self.embedding_dict[word]))\n",
    "        x = self.block(input)\n",
    "        return x\n",
    "    \n",
    "    def generate (self, length = 30, prefix = None):\n",
    "        if prefix is None:\n",
    "            prefix = [self.embedding_dict[np.random.randint(1, 3000)], self.embedding_dict[np.random.randint(1, 3000)]]\n",
    "        text = ''\n",
    "        for word in prefix:\n",
    "            text += word + ' '\n",
    "        for i in range(length):\n",
    "            next_word_vec = self.forward(prefix)\n",
    "            next_word = self.the_most_similar(next_word_vec)\n",
    "            prefix.append(next_word)\n",
    "            prefix.pop(0)\n",
    "            text += next_word + ' '\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68beb7-7b1b-4912-9b98-f10472077002",
   "metadata": {},
   "source": [
    "Набросок генеративной модельки, тут нет обучения, его можно сделать через mse, так как после эмбеддинга норма в пространстве представления\n",
    "слов обрело смысл схожести слов, так что спомощью батч+AdaM и MSE можно оптимизировать модель, разбив текст окном в 3 слова (2 на вход один на сравнение). Скорее всего получится не слишком хорошо, потому что всего 3 скрытых слоя и без фокусов со скипами, но вера есть..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9a0e0-68d1-42f6-9e0d-0c5ee930b166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
